# -*- coding: utf-8 -*-
"""riskpredmodel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WTu_1aoDlzFAfZ8EJZ_RhRPU4yeurnm4
"""

import numpy as np
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

#Load the dataset
df=pd.read_csv("/content/drive/MyDrive/Risk prediction in corporate financial Management using IBM Auto AI service/fraud_dataset.csv")

df.head()

df.tail()

df.info

df.columns

df.describe

df.shape

"""#DATA PREPROCESSING"""

df.isna

df.isnull().any()

df.isnull().sum()

"""#DATA CLEANING IF THERE ARE NULL VALUES IN LOAN AMOUNT"""

df['LoanAmount'].fillna(df['LoanAmount'].mean(), inplace=True)

#IN THIS CASE NO NULL VALUES

df.isnull().sum()

df['Fraud_Risk'].value_counts()

"""Data Visualization"""

#Exploratory data analysis

#import libraries
import matplotlib.pyplot as plt
import seaborn as sns

# Univariate Analysis
plt.figure(figsize=(10, 6))
sns.histplot(df['ApplicantIncome'], bins=10, kde=True)
plt.title('Distribution of ApplicantIncome')
plt.xlabel('ApplicantIncome')
plt.ylabel('Count')
plt.show()

# Bivariate Analysis
plt.figure(figsize=(10, 6))
sns.boxplot(x='Education', y='LoanAmount', data=df)
plt.title('LoanAmount by Education')
plt.xlabel('Education')
plt.ylabel('LoanAmount')
plt.show()

# Multivariate Analysis
plt.figure(figsize=(10, 6))
sns.scatterplot(x='ApplicantIncome', y='LoanAmount',data=df, hue=df['Fraud_Risk'])
plt.title('ApplicantIncome vs. LoanAmount (Fraud Risk)')
plt.xlabel('ApplicantIncome')
plt.ylabel('LoanAmount')
plt.show()

# Correlation matrix
correlation_matrix = df.corr()
print(correlation_matrix)

plt.figure(figsize=(10,8))
sns.heatmap(df.corr(),annot=True)

#Pair Plot
sns.pairplot(df)

"""#IMPORT LIBRARIES"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

X = df.drop('Fraud_Risk', axis=1) # Independent variables
y = df['Fraud_Risk'] # Dependent variable

X

y

scaler = StandardScaler()
X_scaled= scaler.fit_transform(df[['ApplicantIncome', 'CoapplicantIncome']])
X_scaled

"""#Splitting the data set"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

X_train

y_train

X_test

y_test

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""#LINEAR REGRESSION"""

#Model Building
from sklearn.linear_model import LinearRegression
lr=LinearRegression()

#train the model
lr.fit(X_train,y_train)

#test the model
y_pred=lr.predict(X_test)

y_pred #prediction

y_test # Actual outcome

E=y_test-y_pred
E

from sklearn.metrics import r2_score
acc=r2_score(y_pred,y_test)
acc

"""#LOGISTIC REGRESSION"""

logistic_model = LogisticRegression()
logistic_model.fit(X_train, y_train)

# Make predictions
y_pred_logistic = logistic_model.predict(X_test)

# Evaluate the model
accuracy_logistic = accuracy_score(y_test, y_pred_logistic)
print("Accuracy (Logistic Regression):", accuracy_logistic)

"""#RandomForestRegression"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Create and train the Random Forest Regression model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = rf_model.predict(X_test)

# Evaluate the model using mean squared error (MSE)
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

"""#RANDOM FOREST CLASSIFIER"""

rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

# Make predictions
y_pred_rf = rf_model.predict(X_test)

# Evaluate the model
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print("Accuracy (Random Forest):", accuracy_rf)

import pickle

def save_model(model, filename):
    with open(filename, 'wb') as file:
        pickle.dump(model, file)

save_model(rf_model, 'randomforest_model.pkl')

"""#SVC(SUPPORT VECTOR MACHINE)"""

from sklearn.svm import SVC
# Create and train the SVM model
svm = SVC(kernel='linear')
svm.fit(X_train, y_train)

# Make predictions on the test set
y_pred = svm.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

from sklearn.svm import SVC
# Create and train the SVM model
svm = SVC(kernel='poly')
svm.fit(X_train, y_train)

# Make predictions on the test set
y_pred = svm.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

from sklearn.svm import SVC
# Create and train the SVM model
svm = SVC(kernel='rbf')
svm.fit(X_train, y_train)

# Make predictions on the test set
y_pred = svm.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

"""#KNN KNeighborsClassifier"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


# Create and train the KNN classifier
knn = KNeighborsClassifier(n_neighbors=5)  # Specify the number of neighbors (K)
knn.fit(X_train, y_train)

# Make predictions on the test set
y_pred = knn.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

"""#Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


# Create and train the Decision Tree Classifier
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = dt_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

"""Accuracy of decision tree classifier is greater than regression and other classfier models

#Changing the hyper parameters to improve the accuracy
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score



# Create and train the Decision Tree Classifier with tuned hyperparameters
dt_classifier = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_split=10, min_samples_leaf=5, random_state=42)
dt_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = dt_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

"""criterion='gini', max_depth=10, min_samples_split=2, min_samples_leaf=1, random_state=42
These changes in hyper parameters giving the maximum accuracy
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score



# Create and train the Decision Tree Classifier with tuned hyperparameters
dt_classifier = DecisionTreeClassifier(criterion='gini', max_depth=10, min_samples_split=2, min_samples_leaf=1, random_state=42)
dt_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = dt_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

import pickle

def save_model(model, filename):
    with open(filename, 'wb') as file:
        pickle.dump(model, file)

save_model(dt_classifier, 'decision_tree_model.pkl')

"""Function to predict the accuracy from the given inputs

"""

from sklearn.tree import DecisionTreeClassifier

def predict_fraud_risk(gender, married, dependents, education, self_employed, applicant_income, coapplicant_income, loan_amount, loan_term, credit_history_available, housing, locality):
    # Create the input features as a dictionary
    input_data = {
        'Gender': gender,
        'Married': married,
        'Dependents': dependents,
        'Education': education,
        'Self_Employed': self_employed,
        'ApplicantIncome': applicant_income,
        'CoapplicantIncome': coapplicant_income,
        'LoanAmount': loan_amount,
        'Loan_Term': loan_term,
        'Credit_History_Available': credit_history_available,
        'Housing': housing,
        'Locality': locality
    }

    # Convert the input features into a DataFrame
    input_df = pd.DataFrame([input_data])

    # Make predictions on the input data
    predicted_risk = rf_model.predict(input_df)

    return predicted_risk

gender = 1
married = 1
dependents = 0
education = 0
self_employed = 0
applicant_income = 40000
coapplicant_income = 0
loan_amount = 15000
loan_term = 360
credit_history_available = 1
housing = 1
locality = 1

predicted_risk = predict_fraud_risk(gender, married, dependents, education, self_employed, applicant_income, coapplicant_income, loan_amount, loan_term, credit_history_available, housing, locality)
print("Predicted Risk:", predicted_risk)

"""Changing the values to predict risk"""

gender = 1
married = 0
dependents = 0
education = 1
self_employed = 0
applicant_income = 100000
coapplicant_income = 0
loan_amount = 150
loan_term = 360
credit_history_available = 1
housing = 1
locality = 1

predicted_risk = predict_fraud_risk(gender, married, dependents, education, self_employed, applicant_income, coapplicant_income, loan_amount, loan_term, credit_history_available, housing, locality)
print("Predicted Risk:", predicted_risk)

import pickle

def save_model(model, filename):
    with open(filename, 'wb') as file:
        pickle.dump(model, file)


save_model(dt_classifier, 'decision_tree_model.pkl')